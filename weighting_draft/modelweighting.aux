\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{little04-model}
\citation{samsi:review17}
\citation{gelman07}
\citation{ghosh:meeden:97}
\citation{gelman:little:97,park:gelman:bafumi-04,Ghitza:gelman-13}
\citation{hs79}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{groves:couper:98JOS}
\citation{potter88,trim-potter90,modeltrim-elliottandlittle00,elliott07,elliot:JOS16}
\citation{beaumont08}
\citation{rubin76,rubin83-pi}
\citation{gelman07}
\citation{henry:valliant12}
\citation{FPSi:Valliant00}
\citation{robustblup:Chambers:JASA93,robust:Firth:JRSSB98}
\citation{calibration:kott09}
\citation{greg92}
\citation{breidt05}
\citation{little83-pi}
\citation{bnfp:ba15}
\citation{little91,little93}
\citation{fuller09}
\citation{bnfp:ba15}
\citation{pfeffermann93}
\citation{stan-software:2013,stan-manual:2013}
\citation{hoffman-gelman:2012}
\citation{RHweighting,RHreport}
\citation{RHweighting}
\citation{gr-rake93}
\citation{gelman:little:98}
\citation{acsweighting2014}
\@writefile{toc}{\contentsline {section}{\numberline {2}The motivating application}{3}{section.2}}
\newlabel{problem}{{2}{3}{The motivating application}{section.2}{}}
\citation{Breidt08,Dahlke13}
\citation{little91,little93,gelman:little-97,gelmancarlin01}
\@writefile{toc}{\contentsline {section}{\numberline {3}Method}{5}{section.3}}
\newlabel{method}{{3}{5}{Method}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Multilevel regression and poststratification}{5}{subsection.3.1}}
\newlabel{model-based}{{2}{5}{Multilevel regression and poststratification}{equation.3.2}{}}
\citation{gelman07}
\citation{little93}
\citation{modeltrim-elliottandlittle00}
\citation{elliot:JOS16}
\citation{gelman07}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Structured prior distribution}{6}{subsection.3.2}}
\newlabel{normal}{{3}{6}{Structured prior distribution}{equation.3.3}{}}
\citation{anova:gelman:05,gelman06-prior}
\citation{volfovsky:hoff14}
\citation{volfovsky:hoff14}
\newlabel{regression}{{4}{7}{Structured prior distribution}{equation.3.4}{}}
\citation{gelman06-prior}
\citation{grouplasso06}
\citation{horseshoe10}
\citation{hyperprior:Aki16}
\citation{gelman07}
\newlabel{main}{{5}{8}{Structured prior distribution}{equation.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Model-based weights}{8}{subsection.3.3}}
\newlabel{theta-summary}{{6}{8}{Model-based weights}{equation.3.6}{}}
\newlabel{model-w}{{7}{9}{Model-based weights}{equation.3.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Simulation studies}{9}{section.4}}
\newlabel{simulation}{{4}{9}{Simulation studies}{section.4}{}}
\citation{volfovsky:hoff14}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Slightly unbalanced structure}{10}{subsection.4.1}}
\newlabel{3var}{{4.1}{10}{Slightly unbalanced structure}{subsection.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \em  Comparison of prediction and weighting performances on validity of finite population inference under slightly unbalanced design. The y-axis denotes different groups for the mean estimation. The x-axis includes two model-based prediction methods (Str-P, Ind-P), two model-based weighting (Str-W, Ind-W), and three classical weighting methods (PS-W, Rake-W, IP-W). Str-P: model-based prediction under the structure prior; Ind-P: model-based prediction under the independent prior distribution; Str-W: model-based weighting under structure prior; Ind-W: model-based weighting under independent prior distribution; Rake-W: weighting via raking adjustment; PS-W: poststratification weighting; and IP-W: inverse probability of selection weighting. The plots show that the model-based predictions outperform weighting with the smallest RMSE, the smallest SEs, reasonable coverage rates, and comparable bias among all the methods. Model-based weighting inference has smaller RMSE and SEs but more reasonable coverage rates than that with classical weighting.}}{11}{figure.1}}
\newlabel{sim1}{{1}{11}{\em Comparison of prediction and weighting performances on validity of finite population inference under slightly unbalanced design. The y-axis denotes different groups for the mean estimation. The x-axis includes two model-based prediction methods (Str-P, Ind-P), two model-based weighting (Str-W, Ind-W), and three classical weighting methods (PS-W, Rake-W, IP-W). Str-P: model-based prediction under the structure prior; Ind-P: model-based prediction under the independent prior distribution; Str-W: model-based weighting under structure prior; Ind-W: model-based weighting under independent prior distribution; Rake-W: weighting via raking adjustment; PS-W: poststratification weighting; and IP-W: inverse probability of selection weighting. The plots show that the model-based predictions outperform weighting with the smallest RMSE, the smallest SEs, reasonable coverage rates, and comparable bias among all the methods. Model-based weighting inference has smaller RMSE and SEs but more reasonable coverage rates than that with classical weighting}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Very unbalanced structure}{12}{subsection.4.2}}
\newlabel{8var}{{4.2}{12}{Very unbalanced structure}{subsection.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \em  Comparison of generated weights after logarithm transformation and weighted outcome distributions under a very unbalanced design. Str-W: model-based weighting under structure prior; Rake-W: weighting via raking adjustment; and IP-W: inverse probability of selection weighting. Sample: sample distribution of the outcome; and POP: population distribution of the outcome. The model-based weights are more stable and generate a more smoothed outcome distribution after weighting than the raking weights and the inverse probability of selection weights, }}{14}{figure.2}}
\newlabel{sim2-weight}{{2}{14}{\em Comparison of generated weights after logarithm transformation and weighted outcome distributions under a very unbalanced design. Str-W: model-based weighting under structure prior; Rake-W: weighting via raking adjustment; and IP-W: inverse probability of selection weighting. Sample: sample distribution of the outcome; and POP: population distribution of the outcome. The model-based weights are more stable and generate a more smoothed outcome distribution after weighting than the raking weights and the inverse probability of selection weights,}{figure.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Application to Longitudinal Study of Wellbeing}{14}{section.5}}
\newlabel{application}{{5}{14}{Application to Longitudinal Study of Wellbeing}{section.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \em  Efficiency comparison of prediction and weighting performances on finite population domain inference under a very unbalanced design. The left plot examines the mean estimation across the margins defined by the eight weighting variables. The right plots presents the population cell mean estimation. The model-based weighting and prediction under the structure prior distribution yield smaller SEs than those under independent prior. Model-based weighting yields smaller SEs than poststratification weighting.}}{15}{figure.3}}
\newlabel{sim2-se}{{3}{15}{\em Efficiency comparison of prediction and weighting performances on finite population domain inference under a very unbalanced design. The left plot examines the mean estimation across the margins defined by the eight weighting variables. The right plots presents the population cell mean estimation. The model-based weighting and prediction under the structure prior distribution yield smaller SEs than those under independent prior. Model-based weighting yields smaller SEs than poststratification weighting}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \em  Comparison of generated weights after logarithm transformation and weighted distributions of life satisfaction score in the LSW. Str-W: model-based weighting under structured prior; Rake-W: weighting via raking adjustment; IP-W: inverse probability of selection weighting, and Sample: sample distribution of the outcome. The weighted distributions are similar between model-based weights and classical weights, but model-based weights are more stable than classical weights.}}{16}{figure.4}}
\newlabel{lsw-weight}{{4}{16}{\em Comparison of generated weights after logarithm transformation and weighted distributions of life satisfaction score in the LSW. Str-W: model-based weighting under structured prior; Rake-W: weighting via raking adjustment; IP-W: inverse probability of selection weighting, and Sample: sample distribution of the outcome. The weighted distributions are similar between model-based weights and classical weights, but model-based weights are more stable than classical weights}{figure.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces \em  Comparison of prediction and weighting performances on estimating various domain averages for life satisfaction in the LSW. Str-P: model-based prediction under the structured prior; Str-W: model-based weighting under structured prior; Rake-W: weighting via raking adjustment; and PS-W: poststratification weighting. }}{17}{table.1}}
\newlabel{lsw-est}{{1}{17}{\em Comparison of prediction and weighting performances on estimating various domain averages for life satisfaction in the LSW. Str-P: model-based prediction under the structured prior; Str-W: model-based weighting under structured prior; Rake-W: weighting via raking adjustment; and PS-W: poststratification weighting}{table.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \em  Comparison of predictions and weighting performances on estimating life satisfaction score across the margins of four weighting variables in the LSW. Str-P: model-based prediction under the structured prior; Str-W: model-based weighting under structured prior; Rake-W: weighting via raking adjustment; and PS-W: poststratification weighting. Model-based predictions and weighting generate different estimates for several subsets and are generally more efficient comparing with classical weighting.}}{17}{figure.5}}
\newlabel{lsw-mar}{{5}{17}{\em Comparison of predictions and weighting performances on estimating life satisfaction score across the margins of four weighting variables in the LSW. Str-P: model-based prediction under the structured prior; Str-W: model-based weighting under structured prior; Rake-W: weighting via raking adjustment; and PS-W: poststratification weighting. Model-based predictions and weighting generate different estimates for several subsets and are generally more efficient comparing with classical weighting}{figure.5}{}}
\citation{bnfp:ba15}
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion}{18}{section.6}}
\newlabel{discussion}{{6}{18}{Discussion}{section.6}{}}
\citation{rake:little91}
\citation{Kim:Skinner:BM13}
\citation{kang:schafter07}
\bibstyle{chicago}
\bibdata{mrp-weighting}
\bibcite{acsweighting2014}{{1}{2014}{{{ACS Weighting Method}}}{{{ACS Weighting Method}}}}
\bibcite{beaumont08}{{2}{2008}{{Beaumont}}{{Beaumont}}}
\bibcite{Breidt08}{{3}{2008}{{Breidt}}{{Breidt}}}
\bibcite{breidt05}{{4}{2005}{{Breidt et~al.}}{{Breidt, Claeskens, and Opsomer}}}
\bibcite{horseshoe10}{{5}{2010}{{Carvalho et~al.}}{{Carvalho, Polson, and Scott}}}
\bibcite{robustblup:Chambers:JASA93}{{6}{1993}{{Chambers et~al.}}{{Chambers, Dorfman, and Wehrly}}}
\bibcite{samsi:review17}{{7}{2017}{{Chen et~al.}}{{Chen, Elliott, Haziza, Yang, Ghosh, Little, Sefransk, and Thompson}}}
\bibcite{Dahlke13}{{8}{2013}{{Dahlke et~al.}}{{Dahlke, Breidt, Opsomer, and Keilegom}}}
\bibcite{greg92}{{9}{1992}{{Deville and S{\"a}rndal}}{{Deville and S{\"a}rndal}}}
\bibcite{gr-rake93}{{10}{1993}{{Deville et~al.}}{{Deville, Sarndal, and Sautory}}}
\bibcite{elliott07}{{11}{2007}{{Elliott}}{{Elliott}}}
\bibcite{modeltrim-elliottandlittle00}{{12}{2000}{{Elliott and Little}}{{Elliott and Little}}}
\bibcite{robust:Firth:JRSSB98}{{13}{1998}{{Firth and Bennett}}{{Firth and Bennett}}}
\bibcite{fuller09}{{14}{2009}{{Fuller}}{{Fuller}}}
\bibcite{anova:gelman:05}{{15}{2005}{{Gelman}}{{Gelman}}}
\bibcite{gelman06-prior}{{16}{2006}{{Gelman}}{{Gelman}}}
\bibcite{gelman07}{{17}{2007}{{Gelman}}{{Gelman}}}
\bibcite{gelmancarlin01}{{18}{2001}{{Gelman and Carlin}}{{Gelman and Carlin}}}
\bibcite{gelman:little:97}{{19}{1997a}{{Gelman and Little}}{{Gelman and Little}}}
\bibcite{gelman:little-97}{{20}{1997b}{{Gelman and Little}}{{Gelman and Little}}}
\bibcite{gelman:little:98}{{21}{1998}{{Gelman and Little}}{{Gelman and Little}}}
\bibcite{Ghitza:gelman-13}{{22}{2013}{{Ghitza and Gelman}}{{Ghitza and Gelman}}}
\bibcite{ghosh:meeden:97}{{23}{1997}{{Ghosh and Meeden}}{{Ghosh and Meeden}}}
\bibcite{groves:couper:98JOS}{{24}{1995}{{Groves and Couper}}{{Groves and Couper}}}
\bibcite{henry:valliant12}{{25}{2012}{{Henry and Valliant}}{{Henry and Valliant}}}
\bibcite{hoffman-gelman:2012}{{26}{2014}{{Hoffman and Gelman}}{{Hoffman and Gelman}}}
\bibcite{hs79}{{27}{1979}{{Holt and Smith}}{{Holt and Smith}}}
\bibcite{kang:schafter07}{{28}{2007}{{Kang and Schafter}}{{Kang and Schafter}}}
\bibcite{Kim:Skinner:BM13}{{29}{2013}{{Kim and Skinner}}{{Kim and Skinner}}}
\bibcite{calibration:kott09}{{30}{2009}{{Kott}}{{Kott}}}
\bibcite{little83-pi}{{31}{1983}{{Little}}{{Little}}}
\bibcite{little91}{{32}{1991}{{Little}}{{Little}}}
\bibcite{little93}{{33}{1993}{{Little}}{{Little}}}
\bibcite{little04-model}{{34}{2004}{{Little}}{{Little}}}
\bibcite{rake:little91}{{35}{1991}{{Little and Wu}}{{Little and Wu}}}
\bibcite{park:gelman:bafumi-04}{{36}{2005}{{Park et~al.}}{{Park, Gelman, and Bafumi}}}
\bibcite{pfeffermann93}{{37}{1993}{{Pfeffermann}}{{Pfeffermann}}}
\bibcite{hyperprior:Aki16}{{38}{2016}{{Piironen and Vehtari}}{{Piironen and Vehtari}}}
\bibcite{potter88}{{39}{1988}{{Potter}}{{Potter}}}
\bibcite{trim-potter90}{{40}{1990}{{Potter}}{{Potter}}}
\bibcite{rubin76}{{41}{1976}{{Rubin}}{{Rubin}}}
\bibcite{rubin83-pi}{{42}{1983}{{Rubin}}{{Rubin}}}
\bibcite{RHweighting}{{43}{2014}{{Si and Gelman}}{{Si and Gelman}}}
\bibcite{bnfp:ba15}{{44}{2015}{{Si et~al.}}{{Si, Pillai, and Gelman}}}
\bibcite{stan-software:2013}{{45}{2017a}{{{Stan Development Team}}}{{{Stan Development Team}}}}
\bibcite{stan-manual:2013}{{46}{2017b}{{{Stan Development Team}}}{{{Stan Development Team}}}}
\bibcite{FPSi:Valliant00}{{47}{2000}{{Valliant et~al.}}{{Valliant, Dorfman, and Royall}}}
\bibcite{volfovsky:hoff14}{{48}{2014}{{Volfovsky and Hoff}}{{Volfovsky and Hoff}}}
\bibcite{RHreport}{{49}{2014}{{Wimer et~al.}}{{Wimer, Garfinkel, Gelblum, Lasala, Phillips, Si, Teitler, and Waldfogel}}}
\bibcite{elliot:JOS16}{{50}{2016}{{Xia and Elliott}}{{Xia and Elliott}}}
\bibcite{grouplasso06}{{51}{2006}{{Yuan and Lin}}{{Yuan and Lin}}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Stan code}{22}{appendix.A}}
\newlabel{stancode}{{A}{22}{Stan code}{appendix.A}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}R code}{24}{appendix.B}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces \em  Covariates in the outcome (O) and selection (S) models for slightly unbalanced design.}}{27}{table.2}}
\newlabel{s1-design}{{2}{27}{\em Covariates in the outcome (O) and selection (S) models for slightly unbalanced design}{table.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C}Simulation designs}{27}{appendix.C}}
\newlabel{appendix}{{C}{27}{Simulation designs}{appendix.C}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces \em  Assumed regression coefficients in the {\em  outcome} model for the simulation using a slightly unbalanced design.}}{28}{table.3}}
\newlabel{s1-response-coef}{{3}{28}{\em Assumed regression coefficients in the {\em outcome} model for the simulation using a slightly unbalanced design}{table.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces \em  Assumed regression coefficients in the {\em  selection} model for the simulation using a slightly unbalanced design.}}{28}{table.4}}
\newlabel{s1-selection-coef}{{4}{28}{\em Assumed regression coefficients in the {\em selection} model for the simulation using a slightly unbalanced design}{table.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces \em  Covariates in the outcome (O) and selection (S) models for a very unbalanced design.}}{29}{table.5}}
\newlabel{s2-design}{{5}{29}{\em Covariates in the outcome (O) and selection (S) models for a very unbalanced design}{table.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces \em  Assumed regression coefficient values for the outcome (O) and selection (S) models for a very unbalanced design.}}{29}{table.6}}
\newlabel{s2-design-case2}{{6}{29}{\em Assumed regression coefficient values for the outcome (O) and selection (S) models for a very unbalanced design}{table.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces \em  Euclidean distances between the weighted distributions and the population distribution.}}{30}{table.7}}
\newlabel{prob-dist}{{7}{30}{\em Euclidean distances between the weighted distributions and the population distribution}{table.7}{}}
